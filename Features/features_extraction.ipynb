{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import logging\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "import datetime\n",
    "from datetime import timezone \n",
    "\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import ydata_profiling\n",
    "\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "\n",
    "from pycaret.utils import enable_colab \n",
    "from pycaret.classification import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.multicomp import (pairwise_tukeyhsd, MultiComparison)\n",
    "\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ab961",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tsfresh').setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithread\n",
    "jobs = multiprocessing.cpu_count()\n",
    "print('\\n\\nMultithread: ', jobs)\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "# Data\n",
    "#####################################################################################\n",
    "\n",
    "data_path = Path('/home/pzeola/3W/data', '')\n",
    "!pip freeze > /home/pzeola/3W/requirements.txt\n",
    "\n",
    "events_names = {\n",
    "    0: 'Normal',\n",
    "    1: 'Abrupt Increase of BSW',\n",
    "    2: 'Spurious Closure of DHSV',\n",
    "    3: 'Severe Slugging',\n",
    "    4: 'Flow Instability',\n",
    "    5: 'Rapid Productivity Loss',\n",
    "    6: 'Quick Restriction in PCK',\n",
    "    7: 'Scaling in PCK',\n",
    "    8: 'Hydrate in Production Line'}\n",
    "\n",
    "abnormal_classes_codes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "vars = ['P-PDG',\n",
    "        'P-TPT',\n",
    "        'T-TPT',\n",
    "        'P-MON-CKP',\n",
    "        'T-JUS-CKP',\n",
    "        'P-JUS-CKGL',\n",
    "        'T-JUS-CKGL',\n",
    "        'QGL']\n",
    "\n",
    "csv_columns = ['timestamp'] + vars + ['class']\n",
    "\n",
    "#####################################################################################\n",
    "# Feature Extraction parameters\n",
    "#####################################################################################\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "df_fc_p = MinimalFCParameters()\n",
    "df_fc_p['abs_energy'] = None\n",
    "df_fc_p['mean_abs_change'] = None\n",
    "df_fc_p['mean_change'] = None\n",
    "df_fc_p['mean_second_derivative_central'] = None\n",
    "df_fc_p['median'] = None\n",
    "df_fc_p['mean'] = None\n",
    "df_fc_p['standard_deviation'] = None\n",
    "df_fc_p['variation_coefficient'] = None\n",
    "df_fc_p['variance'] = None\n",
    "df_fc_p['skewness'] = None\n",
    "df_fc_p['kurtosis'] = None\n",
    "df_fc_p['root_mean_square'] = None\n",
    "df_fc_p['percentage_of_reoccurring_values_to_all_values'] = None\n",
    "df_fc_p['percentage_of_reoccurring_datapoints_to_all_datapoints'] = None\n",
    "df_fc_p['sample_entropy'] = None\n",
    "df_fc_p['maximum'] = None\n",
    "df_fc_p['minimum'] = None\n",
    "df_fc_p['linear_trend_timewise'] = None\n",
    "print('used features: {}'.format(list(df_fc_p.keys())))\n",
    "\n",
    "#####################################################################################\n",
    "# File input list\n",
    "#####################################################################################\n",
    "def class_and_file_generator(data_path, real=False, simulated=False, drawn=False):\n",
    "    for class_path in data_path.iterdir():\n",
    "        if class_path.is_dir():\n",
    "            class_code = int(class_path.stem)\n",
    "            for instance_path in class_path.iterdir():\n",
    "                if (instance_path.suffix == '.csv'):\n",
    "                    if (simulated and instance_path.stem.startswith('SIMULATED')) or \\\n",
    "                       (drawn and instance_path.stem.startswith('DRAWN')) or \\\n",
    "                       (real and (not instance_path.stem.startswith('SIMULATED')) and \\\n",
    "                       (not instance_path.stem.startswith('DRAWN'))):\n",
    "                        yield class_code, instance_path\n",
    "                        \n",
    "#####################################################################################\n",
    "# Load file into Dataframe\n",
    "#####################################################################################                        \n",
    "def load_instance(class_code, instance_path):\n",
    "    try:\n",
    "        well, instance_id = instance_path.stem.split('_')\n",
    "        df = pd.read_csv(instance_path, sep=',', header=0)\n",
    "        assert (df.columns == csv_columns).all(), 'invalid columns in the file {}: {}'\\\n",
    "            .format(str(instance_path), str(df.columns.tolist()))\n",
    "        \n",
    "        # Disregard transient/fault diff and NaN\n",
    "        df['class'] = np.where(df['class']>100 , class_code, df['class'])\n",
    "        df['class'].fillna(0, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception('error reading file {}: {}'.format(instance_path, e))     \n",
    "        \n",
    "#####################################################################################\n",
    "# Feature Extraction\n",
    "#####################################################################################  \n",
    "def normalize_and_extract_features(window, label):\n",
    "    \n",
    "    # Workaround for NaN columns / NaN por 0\n",
    "    for i in range(len(window[0])-1):\n",
    "        if(np.isnan(window[0,i+1])):\n",
    "            window[0,i+1] = 0  \n",
    "            \n",
    "    # NaN values replaced by Average     ? is this ok ?\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "    # Normalizes the samples (zero mean and unit variance)\n",
    "    df_norm = pd.DataFrame.from_records(scaler.fit_transform(imp_mean.fit_transform(window[:,1:9])).astype('float32'))\n",
    "    df_norm.set_axis(vars, axis=1, inplace=True)\n",
    "    df_norm.insert(loc=0, column='id', value=0)\n",
    "    df_norm.insert(loc=0, column='timestamp', value=0)\n",
    "    df_norm['timestamp'] = df['timestamp']\n",
    "    \n",
    "    # Extracts features from samples\n",
    "    extracted_data = extract_features(df_norm, \n",
    "                         column_id='id', \n",
    "                         column_sort='timestamp', \n",
    "                         default_fc_parameters=df_fc_p,\n",
    "                         impute_function=impute,\n",
    "                         n_jobs=0,\n",
    "                         disable_progressbar=True)\n",
    "    extracted_data.insert(loc=0, column='class', value=label)\n",
    "    extracted_data = extracted_data.reset_index(drop=True)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "\n",
    "# Gets all real/simulated/drawn instances (normal operation only cases discarted)\n",
    "instances = pd.DataFrame(class_and_file_generator(data_path, real=True, simulated=True, drawn=True), columns=['class', 'instance_path'])\n",
    "\n",
    "# Fault instances\n",
    "instances = instances.loc[instances.iloc[:,0].isin(abnormal_classes_codes)].reset_index(drop=True)\n",
    "print('instances:' + str(len(instances)))\n",
    "\n",
    "window_sizes = [500] # se tiver v√°rios tamanhos [150, 500, 600, ...]\n",
    "offset = 150\n",
    "\n",
    "# Raw data windows\n",
    "df = pd.DataFrame(columns=['class', 'data'])\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for window_size in window_sizes:\n",
    "  \n",
    "  df = pd.DataFrame(columns=['class', 'data'])\n",
    "  data = pd.DataFrame()\n",
    "  \n",
    "  # Data ID (csv name)\n",
    "  print('data-s' + str(window_size) + '-o' + str(offset))\n",
    "  \n",
    "  # For each instance with any type of undesirable event\n",
    "  for i, row in instances.iterrows():\n",
    "      \n",
    "      # Loads the current instance\n",
    "      class_code, instance_path = row\n",
    "      print(' ')\n",
    "      print('Instance {}: {} {}'.format(i+1, events_names[class_code], instance_path))\n",
    "      df = load_instance(class_code, instance_path)\n",
    "      \n",
    "      # Moment of fault detection, transition from normal to transient \n",
    "      fault_transition = np.where(df['class'] == class_code)[0][0]\n",
    "      fault_end = fault_transition + len(np.where(df['class'] == class_code)[0])\n",
    "    \n",
    "      for i in range(int((len(df['class']) - window_size)/offset)):\n",
    "        window = df.iloc[i*offset:i*offset+window_size,:].values \n",
    "        extracted_data = normalize_and_extract_features(window, df['class'][i*offset+window_size])\n",
    "        data = data.append(extracted_data) \n",
    "        print(data)\n",
    "          \n",
    "      print(time()-t0)\n",
    "      t0 = time()\n",
    "  \n",
    "  dt = datetime.datetime.now() \n",
    "  utc_time = dt.replace(tzinfo = timezone.utc) \n",
    "  utc_timestamp = utc_time.timestamp()\n",
    "\n",
    "  # Save data as .csv\n",
    "  data.to_csv('all_features.csv')\n",
    "  #data.to_csv('data-s' + str(window_size) + '-n' + str(n_windows) + '-o' + str(window_offset) + '-t' + str(int(utc_timestamp)) + '.csv', index=False)  \n",
    "  \n",
    "  path_x = '/home/pzeola/3W/extracted_features_data/all_features_data-s'+ str(window_size) + '-o' + str(offset) + '.pkl'\n",
    "  \n",
    "  import os.path\n",
    "  if(os.path.exists(path_x)):\n",
    "    # Save binary data\n",
    "    with open('/home/pzeola/3W/extracted_features_data/all_features_data-s' + str(window_size) + '-o' + str(offset) + '.pkl', \"wb\") as f:\n",
    "      pickle.dump(data, f)\n",
    "  else:\n",
    "    data.to_pickle(f\"{path_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open('/home/pzeola/3W/extracted_features_data/all_features_data-s500-o150.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034dfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()\n",
    "print(data.shape)\n",
    "print(data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644aa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns\n",
    "print(len(columns[1:20]))\n",
    "print(columns[1:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
